# Real-Time Collaboration Architecture Concept

This document outlines the conceptual design for implementing secure, real-time collaboration features within the AI Cancer Care CoPilot, addressing key goals outlined in Phase 3 of the project plan. **This revision incorporates graph database concepts to enrich the D2D consultation experience, focusing on lineage, context, and enabling deeper AI insights (like GraphRAG) in the future.**

## Goals

*   Enable secure, real-time **Doctor-to-Doctor (D2D) consultations** related to specific patients.
*   Facilitate the delivery of **real-time alerts and notifications** generated by the AI or system events.
*   Lay the foundation for future real-time features (e.g., shared session awareness).
*   Maintain strict **HIPAA compliance** throughout all real-time interactions.
*   **Leverage Consultation Lineage:** Utilize the history and context of consultations, patient data, and AI interactions (conceptually modeled as a graph) to enable deeper analysis and pattern recognition by both clinicians and AI.

## Core Technology: WebSockets & Conceptual Graph Model

The primary technology enabling real-time, bidirectional communication between the frontend clients and the backend server will be **WebSockets**. However, the underlying **conceptual data model** should be designed with **graph database principles** in mind, even if a dedicated graph DB isn't implemented initially. This allows for richer relationships and future analytical capabilities.

*   **Why WebSockets?** They provide a persistent connection, allowing the server to push data (like new messages or alerts) to clients instantly without the client needing to constantly poll for updates. This is efficient and provides a truly real-time experience.
*   **WebSockets:** Provide the real-time transport layer.
*   **Conceptual Graph Model:** Represent entities (Psatients, Doctors, Consultations, Messages, Data Points, Agents, Conditions, Meds) as nodes and their interactions/relationships as edges. This captures the crucial **lineage** and context.

## Architectural Components

1.  **Frontend (React):**
    *   **WebSocket Client:** Logic to establish and manage WebSocket connections (likely using libraries like `socket.io-client` or native WebSocket API).
    *   **Connection Management:** Handles connecting/disconnecting, potentially joining specific "rooms" or "channels" for different contexts (e.g., a specific patient consult).
    *   **Message Handling:** Logic to send messages (e.g., chat text) and receive/process incoming messages (e.g., displaying new chat messages, showing alerts).
    *   **UI Updates:** Dynamically updates the user interface based on received WebSocket messages.

2.  **Backend (FastAPI):**
    *   **WebSocket Endpoint(s):** FastAPI supports WebSockets directly (`@app.websocket("/ws/...")`). Endpoints will handle client connections, disconnections, and message reception/broadcasting.
    *   **Connection Management:** Maintain a registry of active connections, potentially grouped by user ID, consultation room ID, or patient context.
    *   **Authentication/Authorization:** Secure WebSocket connections. Ensure only authorized users can connect and join specific rooms/channels (likely leveraging existing user session/token authentication). Access control is critical.
    *   **Message Routing/Broadcasting:** Logic to send incoming messages from one client to the appropriate recipient(s) within the same room/context.
    *   **Integration with Core Logic:** Ability for other backend components (e.g., the Orchestrator or specific Agents) to push messages/alerts through the WebSocket manager to targeted clients (e.g., `NotificationAgent` triggering a real-time alert instead of just logging).
    *   **Conceptual Graph Layer:** Business logic should operate as if interacting with a graph, even if implemented over relational DBs or in-memory structures initially. Define clear node types and relationships.
    *   **Graph Query Capability (Future):** Design APIs with the potential to eventually support graph-like queries (e.g., for GraphRAG).

3.  **(Optional/Future) Message Broker:**
    *   For enhanced scalability and decoupling, a message broker (RabbitMQ, Kafka, Google Pub/Sub) could sit between the core backend logic and the WebSocket handler. Agents would publish events to the broker, and the WebSocket service would subscribe and push relevant events to clients. This adds complexity but improves resilience and scaling.
    *   *(POC Scope: Likely start with direct WebSocket handling in FastAPI.)*

4.  **Security Layer:**
    *   **Encryption:** WebSocket connections must use secure protocols (`wss://` instead of `ws://` in production, typically handled by the deployment environment/reverse proxy like Nginx). End-to-end encryption considerations for message content if required beyond transport layer security.
    *   **Access Control:** Strict authorization checks before allowing connection and joining specific communication channels/rooms.
    *   **Auditing:** Logging key real-time events (connections, disconnections, message sends - excluding sensitive content) to a secure, off-chain audit log.

## HIPAA Compliance Considerations

Maintaining HIPAA compliance is paramount when implementing real-time features involving potential PHI. Here's how the proposed architecture addresses key requirements:

1.  **Authentication & Authorization:**
    *   WebSocket connections will require authentication using the application's standard secure methods (e.g., validating JWT tokens/session cookies) *before* the connection is fully established.
    *   Authorization checks will be performed server-side before allowing a user to join a specific patient-related room/channel, ensuring they have legitimate access rights to that context.

2.  **Data Minimization:**
    *   Real-time messages (especially initial notifications/alerts) will be designed to convey necessary information (e.g., urgency, type, patient ID) without transmitting excessive PHI.
    *   Detailed information should be accessed via standard secure API calls within the main application interface, prompted by the real-time event.
    *   Chat messages, while potentially containing PHI, are confined to the specific, authorized participants within a secure communication channel.

3.  **Encryption:**
    *   **Transport Encryption:** Secure WebSocket protocol (`wss://`) is mandatory in production environments to encrypt data in transit.
    *   **Content Encryption:** While end-to-end encryption of message content is complex, reliance on strong transport encryption (`WSS`) combined with robust server-side access control is the primary strategy.

4.  **Auditing:**
    *   Comprehensive **off-chain** audit logs will record significant real-time events: user connections/disconnections, authentication success/failure for rooms, room joining/leaving, and message send metadata (sender, room, timestamp - **NOT message content**).
    *   These logs are crucial for security monitoring and compliance reviews and must be stored securely.

5.  **Secure Storage (Off-Chain):**
    *   Any persistent storage of consultation transcripts or message history containing PHI will occur exclusively within the secure, HIPAA-compliant **off-chain** database, subject to the same access controls as other patient data.

6.  **Business Associate Agreements (BAAs):**
    *   If using third-party cloud infrastructure (e.g., managed WebSocket services, databases), appropriate BAAs must be established with the provider.

7.  **Graph Data & PHI:** If/when a graph database is implemented, it must be hosted within the secure, HIPAA-compliant environment. Relationships should be carefully designed to avoid embedding excessive PHI directly within edge properties where possible. Focus on linking to secure, off-chain data.

By adhering to these principles, the real-time features can provide significant collaborative benefits while maintaining the necessary security and privacy standards for handling PHI.

## Example Workflow: Doctor-to-Doctor Consult (Graph-Aware)

1.  **Initiation:** Dr. A, viewing Patient X's elevated glucose result (a node), clicks "Consult Dr. B".
2.  **API Request:** Frontend sends request, including Dr. B, Patient X ID, and the initiating context (Lab Result ID).
3.  **Backend Setup (Graph Concept):**
    *   Verify authorization.
    *   Create a `Consultation` node, link it (`ABOUT_PATIENT`) to Patient X node, link Dr. A (`PARTICIPATES_IN`), and link (`INITIATED_FROM`) to the specific `LabResult` node.
    *   Generate a unique room ID (can be property of `Consultation` node).
    *   Log the initiation.
4.  **Notification:** Backend notifies Dr. B via WebSocket, including room ID.
5.  **Acceptance:** Dr. B accepts.
6.  **Connection & Context Loading:**
    *   Both frontends connect to the WebSocket room.
    *   Backend performs a conceptual graph query for the `Consultation` node (based on room ID) and retrieves its immediate context (Patient, Participants, Initiating Item) to send to the clients for initial UI display.
7.  **Chat & Graph Evolution:**
    *   Dr. A types a message mentioning "Metformin adjustment". Backend conceptually creates a `Message` node linked to the `Consultation`, links Dr. A (`SENT_BY`), and potentially links (`MENTIONS`) to the `Medication` node for Metformin.
    *   Backend broadcasts the message.
    *   Dr. B receives and displays.
8.  **(Potential GraphRAG / Agent Integration):**
    *   Dr. B types `/graph Show timeline of discussions involving glucose levels and medication adjustments.`
    *   Backend translates this, performs a conceptual graph traversal (finding `Consultation` -> `Message` -> `MENTIONS` -> `LabResult`[glucose] / `Medication` nodes for this Patient, ordered by time), retrieves the relevant context.
    *   This context is passed to an LLM along with the query.
    *   The LLM generates a response (e.g., a timeline summary).
    *   Backend sends the AI response back into the WebSocket room as a specific message type.
9.  **Termination:** Standard cleanup.
10. **Cleanup & Lineage Preservation:** Close room, disconnect clients, log end event. The `Consultation` node and its relationships remain in the conceptual graph, preserving the lineage.

## Enhanced Consultation Features & UI Concepts (Graph-Infused Brainstorming)

Leveraging WebSockets and a **conceptual graph model** allows for a more intelligent and context-aware D2D consult feature:

*   **Contextual Interaction (Graph-Powered):**
    *   **Initiation with Graph Links:** Initiation links the new `Consultation` node directly to the relevant data point (Lab, Note, etc.) node in the conceptual graph.
    *   **Graph-Retrieved Context:** Joining retrieves not just the consult details but relevant connected nodes (initiating item, recent related events) via a conceptual graph query, providing richer initial context.
    *   **Shared Graph Snippets:** (Advanced UI) Potentially visualize small, relevant subgraphs within the consult panel showing connections between discussed entities.

*   **AI Agent Integration (Graph-Aware):**
    *   **Structured Agent Input:** Agent commands (e.g., `/check-interactions`) can trigger backend graph queries to fetch structured data (e.g., list of current medication nodes for the patient) for more reliable agent input.
    *   **Agent Actions as Nodes:** Agent invocations and their outputs (drafts, summaries) are recorded as nodes linked to the consultation, creating an auditable trail and enabling queries about agent usage.
    *   **GraphRAG for Complex Questions:** Enable natural language queries (`/graph ...`) that trigger graph traversals to gather deep, historical, and relational context before invoking the LLM, allowing for insights beyond simple data retrieval (e.g., "Summarize all previous consult discussions about managing side effect X for this patient").

*   **UI/UX & Component Design (Reflecting Lineage):**
    *   **`ConsultationPanel.jsx`:** Remains the core UI, but designed to potentially display graph-derived context (e.g., linked entities, timeline view).
    *   **Timeline View:** A sidebar driven by graph queries, showing chronologically linked consultations, patient events, and agent actions.
    *   **Entity Linking in Chat:** Automatically link text mentions of known graph entities (meds, conditions) to allow hovering/clicking for more info or related history retrieval.
    *   **Visualizing Connections (Future):** Explore subtle ways to visualize the connections between messages, data points, and previous consultations without cluttering the UI.

## Benefits

*   **Technical:** Enables efficient, low-latency, bidirectional communication required for interactive features.
*   **Non-Technical (Clinician):**
    *   **Seamless Communication:** Facilitates quick consultations and advice-seeking directly within the patient context, reducing the need to switch applications or make phone calls.
    *   **Faster Alerts:** Critical information (e.g., urgent lab results flagged by AI) can be delivered instantly, potentially improving response times.
    *   **Improved Collaboration:** Creates a more dynamic and collaborative environment for the care team.
*   **Patient Benefit:** Faster communication and alerts among the care team can lead to quicker decisions, more coordinated care, and potentially improved safety and outcomes.
*   **Deeper Insights:** Enables AI and clinicians to uncover patterns and connections across consultations and patient history via graph traversal and analysis.
*   **Enhanced Auditability:** Creates a rich, interconnected lineage of communication and actions.
*   **Foundation for Advanced AI:** Provides the structured data needed for more sophisticated AI reasoning (GraphRAG, GDS).

## Next Steps (Implementation Refined - Graph-Aware Design)

1.  **Design & Create `ConsultationPanel.jsx`:** Define UI structure. Include placeholders for future graph-derived elements (e.g., context panel, timeline view hook).
2.  **Implement Initiation Flow:** Add UI elements. Backend logic should conceptually create/link the `Consultation` node and related nodes, even if just storing IDs in a relational structure for now.
3.  **Backend WebSocket Enhancements (`main.py`):**
    *   Handle new message types (`chat_message`, `agent_command`). Business logic should operate on the *conceptual* graph model.
    *   For `agent_command`, fetch necessary context (potentially simulating graph traversal if no graph DB) before calling the orchestrator.
4.  **Frontend `ConsultationPanel.jsx` Logic:**
    *   Connect via `useWebSocket`.
    *   Send/Receive messages. Display results. Render basic context passed on join.
5.  **(Conceptual) GraphRAG Endpoint:** Define a placeholder structure for how `/graph` commands might be handled in the future (parsing, conceptual query, LLM call with context).
6.  **Notification System (Placeholder/Basic):** As before.
7.  **Authentication/Authorization Refinement:** As before. 

### Detailed Plan: Implement AI Consult Focus (Demo Scope)

This sub-plan details the steps to generate and display an AI-powered summary explaining the likely reason for the consultation, enhancing the context for the joining doctor (Dr. B).

*   **7a. Frontend - Trigger with Specific Context:**
    *   Modify the "Consult Colleague" button's `onClick` in `PatientRecordViewer.jsx` to consistently send a structured `initialContext` object with keywords known to trigger backend enrichment (e.g., `{ type: 'lab_result', component: 'Creatinine', value: 1.3, description: 'Reviewing elevated Creatinine 1.3' }`). This simplifies context capture for the demo.
*   **7b. Backend - Refine Context Enrichment (`initiate_consult` handler):**
    *   Ensure the keyword/type matching logic reliably finds relevant `relatedItems` (History, Meds, Labs) from mock data based on the specific demo `initialContext`.
*   **7c. Backend - Construct "Consult Focus" Prompt (`initiate_consult` handler):**
    *   Create the detailed prompt template for the LLM, inserting initiator/recipient names, patient diagnosis, the `initialContext.description`, and the found `relatedItems`. Frame the request to ask for the likely clinical question or point of discussion.
*   **7d. Backend - Call LLM for Focus Statement (`initiate_consult` handler):**
    *   Use `orchestrator.handle_prompt` (assuming it can process the instructional prompt) or a direct LLM utility function to execute the prompt generated in step 7c.
*   **7e. Backend - Package & Send Enriched Context (`initiate_consult` handler):**
    *   Extract the text summary generated by the LLM.
    *   Add this text to the `enrichedContext` object under a new key, e.g., `consultFocusStatement`.
    *   Send the `consult_request` message containing this full `enrichedContext` (description, relatedItems, consultFocusStatement) to Dr. B.
*   **7f. Frontend - Receive & Display Focus (`PatientRecordViewer.jsx`):**
    *   Update state (`incomingConsultRequest`, `currentConsultation`) to expect `context.consultFocusStatement`.
    *   Modify the "Joining Consult" view (`isJoiningConsult === true`) to display the `consultFocusStatement` prominently within the "Consultation Context" section (e.g., labeled "AI Suggested Focus:"). 